{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Predict how long it takes for colleges to implement vaccine requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feature Engineering\n",
    "Some was done in previous notebook, but most will be done here. I'm using the cleaned vaccine data from my 'Vaccine Mandates' notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>College</th>\n",
       "      <th>ranking</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>zip</th>\n",
       "      <th>announce_date</th>\n",
       "      <th>Type</th>\n",
       "      <th>State_x</th>\n",
       "      <th>all_employee_vacc</th>\n",
       "      <th>some_employee_vacc</th>\n",
       "      <th>...</th>\n",
       "      <th>Region</th>\n",
       "      <th>Division</th>\n",
       "      <th>zip_str</th>\n",
       "      <th>cleaned_name_list</th>\n",
       "      <th>2020.student.size</th>\n",
       "      <th>school.name</th>\n",
       "      <th>school.zip</th>\n",
       "      <th>id</th>\n",
       "      <th>cleaned_school.name_list</th>\n",
       "      <th>name_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelphi University</td>\n",
       "      <td>171</td>\n",
       "      <td>NY</td>\n",
       "      <td>Garden City</td>\n",
       "      <td>11530</td>\n",
       "      <td>116.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>Middle Atlantic</td>\n",
       "      <td>11530</td>\n",
       "      <td>['adelphi']</td>\n",
       "      <td>5076.0</td>\n",
       "      <td>Adelphi University</td>\n",
       "      <td>11530</td>\n",
       "      <td>188429.0</td>\n",
       "      <td>['adelphi']</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American University</td>\n",
       "      <td>78</td>\n",
       "      <td>DC</td>\n",
       "      <td>Washington</td>\n",
       "      <td>20016</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>DC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>South</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>20016</td>\n",
       "      <td>['american']</td>\n",
       "      <td>7510.0</td>\n",
       "      <td>American University</td>\n",
       "      <td>20016</td>\n",
       "      <td>131159.0</td>\n",
       "      <td>['american']</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona State University</td>\n",
       "      <td>116</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>85287</td>\n",
       "      <td>197.0</td>\n",
       "      <td>Public</td>\n",
       "      <td>AZ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>West</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>85287</td>\n",
       "      <td>['arizona', 'state']</td>\n",
       "      <td>62633.0</td>\n",
       "      <td>Arizona State University Campus Immersion</td>\n",
       "      <td>85287</td>\n",
       "      <td>104151.0</td>\n",
       "      <td>['arizona', 'state', 'immersion']</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aurora University</td>\n",
       "      <td>302</td>\n",
       "      <td>IL</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>60506</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>60506</td>\n",
       "      <td>['aurora']</td>\n",
       "      <td>4123.0</td>\n",
       "      <td>Aurora University</td>\n",
       "      <td>60506</td>\n",
       "      <td>143118.0</td>\n",
       "      <td>['aurora']</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bellarmine University</td>\n",
       "      <td>202</td>\n",
       "      <td>KY</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>40205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>KY</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>South</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>40205</td>\n",
       "      <td>['bellarmine']</td>\n",
       "      <td>2431.0</td>\n",
       "      <td>Bellarmine University</td>\n",
       "      <td>40205</td>\n",
       "      <td>156286.0</td>\n",
       "      <td>['bellarmine']</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    College  ranking state         city    zip  announce_date  \\\n",
       "0        Adelphi University      171    NY  Garden City  11530          116.0   \n",
       "1       American University       78    DC   Washington  20016           13.0   \n",
       "2  Arizona State University      116    AZ        Tempe  85287          197.0   \n",
       "3         Aurora University      302    IL       Aurora  60506          139.0   \n",
       "4     Bellarmine University      202    KY   Louisville  40205            NaN   \n",
       "\n",
       "      Type State_x  all_employee_vacc  some_employee_vacc  ...     Region  \\\n",
       "0  Private      NY                  0                   0  ...  Northeast   \n",
       "1  Private      DC                  1                   0  ...      South   \n",
       "2   Public      AZ                  1                   0  ...       West   \n",
       "3  Private      IL                  1                   0  ...    Midwest   \n",
       "4  Private      KY                  1                   0  ...      South   \n",
       "\n",
       "             Division  zip_str     cleaned_name_list  2020.student.size  \\\n",
       "0     Middle Atlantic    11530           ['adelphi']             5076.0   \n",
       "1      South Atlantic    20016          ['american']             7510.0   \n",
       "2            Mountain    85287  ['arizona', 'state']            62633.0   \n",
       "3  East North Central    60506            ['aurora']             4123.0   \n",
       "4  East South Central    40205        ['bellarmine']             2431.0   \n",
       "\n",
       "                                 school.name  school.zip        id  \\\n",
       "0                         Adelphi University       11530  188429.0   \n",
       "1                        American University       20016  131159.0   \n",
       "2  Arizona State University Campus Immersion       85287  104151.0   \n",
       "3                          Aurora University       60506  143118.0   \n",
       "4                      Bellarmine University       40205  156286.0   \n",
       "\n",
       "            cleaned_school.name_list  name_similarity  \n",
       "0                        ['adelphi']         1.000000  \n",
       "1                       ['american']         1.000000  \n",
       "2  ['arizona', 'state', 'immersion']         0.816497  \n",
       "3                         ['aurora']         1.000000  \n",
       "4                     ['bellarmine']         1.000000  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacc_data = pd.read_csv('vacc_mandates_cleaned_school.csv')\n",
    "vacc_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, drop unnecessary columns (i.e., ones that won't be used as features in my model). Drop names, locations (as I extracted data from them) and ```state_pol```, as that was from the Chronicle data but I found different political data myself. Also dropping records of employee vaccination and boosters, as I'm trying to predict original student vaccination. I will consider ```all_students_vacc``` instead of ```res_students_vacc``` as it'll be less dependent on each college's dorm situations. Also drop ```Division``` as I don't have that much data, so using the more broad category of ```Region``` will probably be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_data.drop(columns=['College', 'state', 'city', 'zip', 'State_x', 'state_fips', \n",
    "                        'STCOUNTYFP', 'county_fips', 'county_fips_str', 'state_pol', \n",
    "                        'State_y', 'State Code', 'Division', 'zip_str', 'cleaned_name_list',\n",
    "                        'school.name', 'school.zip', 'id', 'cleaned_school.name_list', 'name_similarity',\n",
    "                        'all_employee_vacc', 'some_employee_vacc', 'res_students_vacc'], \n",
    "               inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>announce_date</th>\n",
       "      <th>Type</th>\n",
       "      <th>all_students_vacc</th>\n",
       "      <th>booster</th>\n",
       "      <th>median_income</th>\n",
       "      <th>total_population</th>\n",
       "      <th>avg_hhsize</th>\n",
       "      <th>avg_community_level</th>\n",
       "      <th>political_control_state</th>\n",
       "      <th>county_vote_diff</th>\n",
       "      <th>Region</th>\n",
       "      <th>2020.student.size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>116.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47254.0</td>\n",
       "      <td>1355683.0</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.624352</td>\n",
       "      <td>Dem</td>\n",
       "      <td>0.059304</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>5076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52328.0</td>\n",
       "      <td>701974.0</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>Dem</td>\n",
       "      <td>0.867763</td>\n",
       "      <td>South</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116</td>\n",
       "      <td>197.0</td>\n",
       "      <td>Public</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34032.0</td>\n",
       "      <td>4412779.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.492925</td>\n",
       "      <td>Rep</td>\n",
       "      <td>-0.028354</td>\n",
       "      <td>West</td>\n",
       "      <td>62633.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>302</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35433.0</td>\n",
       "      <td>531756.0</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.568831</td>\n",
       "      <td>Dem</td>\n",
       "      <td>0.105015</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>4123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32123.0</td>\n",
       "      <td>768419.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.062827</td>\n",
       "      <td>Div</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>South</td>\n",
       "      <td>2431.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranking  announce_date     Type  all_students_vacc  booster  median_income  \\\n",
       "0      171          116.0  Private                  1        0        47254.0   \n",
       "1       78           13.0  Private                  1        1        52328.0   \n",
       "2      116          197.0   Public                  0        0        34032.0   \n",
       "3      302          139.0  Private                  1        0        35433.0   \n",
       "4      202            NaN  Private                  1        0        32123.0   \n",
       "\n",
       "   total_population  avg_hhsize  avg_community_level political_control_state  \\\n",
       "0         1355683.0        2.62             0.624352                     Dem   \n",
       "1          701974.0        2.19             0.726562                     Dem   \n",
       "2         4412779.0        2.64             0.492925                     Rep   \n",
       "3          531756.0        2.81             0.568831                     Dem   \n",
       "4          768419.0        2.25             1.062827                     Div   \n",
       "\n",
       "   county_vote_diff     Region  2020.student.size  \n",
       "0          0.059304  Northeast             5076.0  \n",
       "1          0.867763      South             7510.0  \n",
       "2         -0.028354       West            62633.0  \n",
       "3          0.105015    Midwest             4123.0  \n",
       "4          0.133300      South             2431.0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacc_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As rankings are tied from 299-391 (see \"Vaccine Mandates.ipynb\") and a change in ranking won't usually signal a large change in a college's operations unless they move to a new echelon, I will place the rankings into bins. The rankings are fairly arbitrary besides 299-391. I isolated the top 20 because they often are spoken of in a different way. Then, I separated the rest of the top 100 (another arbitrary cut, but one that makes sense when talking about top colleges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_data['ranking'] = pd.cut(vacc_data['ranking'], bins=[0, 20, 100, 200, 298, 400], labels=['a', 'b', 'c', 'd', 'e'], right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I need to figure out my target variable. Explore the two possibilities--categorical variable for vaccination status or continuous variable for days after first announcement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    141\n",
       "0     12\n",
       "Name: all_students_vacc, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacc_data['all_students_vacc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_students_vacc  booster\n",
       "1                  0          99\n",
       "                   1          42\n",
       "0                  0          12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacc_data[['all_students_vacc', 'booster']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacc_data['announce_date'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_data.dropna(subset=['announce_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With only 14 colleges not requiring the vaccine, there's likely not enough data to train a good model. So, I can drop these and do a regression estimating how long it takes for a college to institute a vaccination requirement, under the assumption that they will make one. This won't be as useful, but can help gauge each college's decision times and urgency regarding their requirements.\n",
    "\n",
    "Note that in the future, I can also try to predict if a college that already had a vaccine requirement will require a booster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = vacc_data['announce_date'] # Note: is continuous\n",
    "features_date = vacc_data.drop(columns=['announce_date', 'all_students_vacc', 'booster'])\n",
    "target_booster = vacc_data['booster'] # Note: is continuous\n",
    "features_booster = vacc_data.drop(columns=['all_students_vacc', 'booster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make sure all the vars are the correct type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ranking                    category\n",
       "announce_date               float64\n",
       "Type                         object\n",
       "all_students_vacc             int64\n",
       "booster                       int64\n",
       "median_income               float64\n",
       "total_population            float64\n",
       "avg_hhsize                  float64\n",
       "avg_community_level         float64\n",
       "political_control_state      object\n",
       "county_vote_diff            float64\n",
       "Region                       object\n",
       "2020.student.size           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacc_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ranking', 'announce_date', 'Type', 'all_students_vacc', 'booster',\n",
       "       'median_income', 'total_population', 'avg_hhsize',\n",
       "       'avg_community_level', 'political_control_state', 'county_vote_diff',\n",
       "       'Region', '2020.student.size'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacc_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use one-hot encoding for the categorical variables. Note that my preprocessing is copied/based on [this sklearn course](https://inria.github.io/scikit-learn-mooc/python_scripts/03_categorical_pipeline_column_transformer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "categorical_preprocessor = OneHotEncoder(drop='first') # drop to avoid multicollinearity\n",
    "numerical_preprocessor = StandardScaler() # normalize data to make it easier for sklearn models to handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "type_encoded = categorical_preprocessor.fit_transform(vacc_data[['Type']])\n",
    "print(type_encoded.toarray()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a pipeline, apply to all categorical features. Also, standardize numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['ranking', 'Type', 'political_control_state', 'Region']\n",
    "numerical_columns = list(set(features_date.columns).difference(categorical_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer # splits the column, transforms each subset differently, then concatenates\n",
    "preprocessor = ColumnTransformer([('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "                                  ('standard_scaler', numerical_preprocessor, numerical_columns)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split into testing and training (which randomizes data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_date, target_date, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use normal linear regression first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('one-hot-encoder',\n",
       "                                                  OneHotEncoder(drop='first'),\n",
       "                                                  ['ranking', 'Type',\n",
       "                                                   'political_control_state',\n",
       "                                                   'Region']),\n",
       "                                                 ('standard_scaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['avg_hhsize',\n",
       "                                                   'median_income',\n",
       "                                                   'total_population',\n",
       "                                                   'county_vote_diff',\n",
       "                                                   'avg_community_level',\n",
       "                                                   '2020.student.size'])])),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(preprocessor, LinearRegression())\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4361647632216755"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add regularization--let's try Lasso as some features may note be important, using cross validation to select the hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('one-hot-encoder',\n",
       "                                                  OneHotEncoder(drop='first'),\n",
       "                                                  ['ranking', 'Type',\n",
       "                                                   'political_control_state',\n",
       "                                                   'Region']),\n",
       "                                                 ('standard_scaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['avg_hhsize',\n",
       "                                                   'median_income',\n",
       "                                                   'total_population',\n",
       "                                                   'county_vote_diff',\n",
       "                                                   'avg_community_level',\n",
       "                                                   '2020.student.size'])])),\n",
       "                ('lassocv', LassoCV())])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "pipe = make_pipeline(preprocessor, LassoCV())\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40396006163919096"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also not working too well. Try ensemble learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe should output a rank (i.e., which universities acted first)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Predicting Booster\n",
    "*TODO* Can we create a classification model that tells us whether or not universities have a vaccine mandate? Is there even enough data to do this? I will try to get the data from another source. This will be a more interesting task as it has more data and is not subject to the problems with the first model when encountering a university that didn't act make one of the recorded COVID decisions. also, it may provide better results.\n",
    "\n",
    "First, I'll train a model to classify the universities that required the vaccine and those that didn't. Then, I may try a multi-level classification approach if the data I find are rich enough, with three options: one for no mandate, one for a regular mandate, and one for a booster mandate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "Find papers that illustrate where COVID-related sentiment comes from and what factors may cause people/administrations to act as they do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "- https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
